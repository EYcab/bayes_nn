[default]
CUDA = True             # Do you want to use CUDA for PyTorch?
batch_size = 64         # Batch size during training
max_steps = 1500        # Maximum SGD steps on the training
lr = 0.01               # Learning rate
momentum = 0.5          # Momentum for the SGD updater
log_interval = 100      # Interval on which to log the train performance
drop_prob = 0.5         # Dropping probability for the dropout
num_filters = 8         # Number of convolutional filters in the first CONV layer
num_fc = 14             # Number of neurons in the fully connected layer
weight_decay = 0.0001   # Weight decay constant for the Langevin training

# Method string for which experiments to perform
# <METHOD NAME>,<METHOD VARIABLE NAME>,<START VALUE>,<STOP VALUE>|
# For defining a new experiment, a function in util/mutilation.py must have the method name
experiments = rotation,angle,0,180|noise,sigma,0,1
# |noise_clip,sigma,0,1

[sampling]
num_experiments = 25    # Number of interpolations between START_VALUE and STOP_VALUE in an experiment
num_runs = 12           # For dropout, this is the number of runs with different masks.
                        # For Bootstrap and Langevin, this is the number of parameter samples
batch_size_test = 14    # Batch size during testing

[langevin]
burn_in = 2500          # Burn in period. The first <burn_in> samples will be discarded
sample_every = 1000     # Every ... samples a parameter will be saved
