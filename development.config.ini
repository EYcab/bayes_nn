[default]
# Do you want to use CUDA for PyTorch?
CUDA = True
# Batch size during training
batch_size = 3
# Maximum SGD steps on the training
max_steps = 1500
# Learning rate
lr = 0.01
# Momentum for the SGD updater
momentum = 0.5
# Interval on which to log the train performance
log_interval = 100
# Dropping probability for the dropout
drop_prob = 0.5
# Number of convolutional filters in the first CONV layer
num_filters = 8
# Number of neurons in the fully connected layer
num_fc = 14
# Weight decay constant for the Langevin training
weight_decay = 0.0001

# Method string for which experiments to perform
# <METHOD NAME>,<METHOD VARIABLE NAME>,<START VALUE>,<STOP VALUE>|
# For defining a new experiment, a function in util/mutilation.py must have the method name
experiments = rotation,angle,0,90|noise,sigma,0,2
# |noise_clip,sigma,0,1

[sampling]
# Number of interpolations between START_VALUE and STOP_VALUE in an experiment
num_experiments = 35
# For dropout, this is the number of runs with different masks.
# For Bootstrap and Langevin, this is the number of parameter samples
# Please smile if you know why this number is twelve :)
num_runs = 12
# Batch size during testing
batch_size_test = 64

[langevin]
# Burn in period. The first <burn_in> samples will be discarded
burn_in = 2500
# Every ... samples a parameter will be saved
sample_every = 1000